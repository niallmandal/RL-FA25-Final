{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bec6ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Multi-asset PPO trading setup\n",
    "\n",
    "Assumptions:\n",
    "- prices: np.ndarray of shape (T, N_assets)\n",
    "- features: np.ndarray of shape (T, F), already aligned with prices by time\n",
    "- At each step t:\n",
    "    * Agent observes state s_t = [features_t, position_pct, cash_pct]\n",
    "    * Agent outputs a_t in [-1,1]^N_assets (one PPO output per asset)\n",
    "    * We follow your mapping:\n",
    "        E_t = cash_t + sum(p_i * S_i_t)\n",
    "        For N assets, each asset gets E_t / N as base scale:\n",
    "            V_i = (E_t / N) * a_i\n",
    "            N_i_target = V_i / S_i_t\n",
    "            Delta_i = N_i_target - p_i (trade size)\n",
    "    * Reward is portfolio return from t to t+1 minus transaction costs\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.distributions import Normal\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# 1. Trading Environment (gymnasium style)\n",
    "# ==========================\n",
    "\n",
    "class MultiAssetTradingEnv(gym.Env):\n",
    "    \"\"\"\n",
    "    FinRL-style multi-asset trading environment with continuous actions,\n",
    "    following your order-size mapping diagram.\n",
    "\n",
    "    State: [features_t, position_value_pct, cash_pct]\n",
    "    Action: Box[-1,1] of size N_assets\n",
    "    Reward: portfolio return from t to t+1 (after trades) minus transaction cost\n",
    "\n",
    "    Gymnasium API:\n",
    "        reset() -> obs, info\n",
    "        step(action) -> obs, reward, terminated, truncated, info\n",
    "    \"\"\"\n",
    "\n",
    "    metadata = {\"render_modes\": [\"human\"]}\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        prices: np.ndarray,\n",
    "        features: np.ndarray,\n",
    "        initial_cash: float = 100000.0,\n",
    "        transaction_cost: float = 0.0005,  # 5 bps per dollar traded\n",
    "        render_mode: str | None = None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        assert prices.shape[0] == features.shape[0], \\\n",
    "            \"prices and features must have the same time dimension\"\n",
    "\n",
    "        self.prices = prices.astype(np.float32)\n",
    "        self.features = features.astype(np.float32)\n",
    "\n",
    "        self.T, self.n_assets = self.prices.shape\n",
    "        self.feature_dim = self.features.shape[1]\n",
    "\n",
    "        self.initial_cash = float(initial_cash)\n",
    "        self.transaction_cost = float(transaction_cost)\n",
    "        self.render_mode = render_mode\n",
    "\n",
    "        # Action: continuous allocation signals in [-1,1] for each asset\n",
    "        self.action_space = spaces.Box(\n",
    "            low=-1.0,\n",
    "            high=1.0,\n",
    "            shape=(self.n_assets,),\n",
    "            dtype=np.float32,\n",
    "        )\n",
    "\n",
    "        # Observation: features + position percentage per asset + cash percentage\n",
    "        self.obs_dim = self.feature_dim + self.n_assets + 1\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=-np.inf,\n",
    "            high=np.inf,\n",
    "            shape=(self.obs_dim,),\n",
    "            dtype=np.float32,\n",
    "        )\n",
    "\n",
    "        # Internal state\n",
    "        self._reset_internal_state()\n",
    "\n",
    "    # ---------- internal helpers ----------\n",
    "\n",
    "    def _reset_internal_state(self):\n",
    "        self.t = 0  # current time index\n",
    "        self.positions = np.zeros(self.n_assets, dtype=np.float32)  # shares\n",
    "        self.cash = float(self.initial_cash)\n",
    "        self.equity = float(self.initial_cash)\n",
    "\n",
    "    def _get_observation(self) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Build observation vector at current time index self.t:\n",
    "        [features_t, position_value_pct, cash_pct]\n",
    "        \"\"\"\n",
    "        features_t = self.features[self.t]  # shape (F,)\n",
    "        price_t = self.prices[self.t]       # shape (N_assets,)\n",
    "\n",
    "        position_values = self.positions * price_t  # dollar value per asset\n",
    "        total_equity = self.equity + 1e-8\n",
    "\n",
    "        position_pct = position_values / total_equity  # shape (N_assets,)\n",
    "        cash_pct = np.array([self.cash / total_equity], dtype=np.float32)\n",
    "\n",
    "        obs = np.concatenate(\n",
    "            [features_t, position_pct.astype(np.float32), cash_pct],\n",
    "            axis=0\n",
    "        )\n",
    "        return obs.astype(np.float32)\n",
    "\n",
    "    # ---------- gymnasium API ----------\n",
    "\n",
    "    def reset(self, *, seed: int | None = None, options: dict | None = None):\n",
    "        \"\"\"\n",
    "        Gymnasium reset: returns (obs, info)\n",
    "        \"\"\"\n",
    "        super().reset(seed=seed)\n",
    "        self._reset_internal_state()\n",
    "        obs = self._get_observation()\n",
    "        info = {}\n",
    "        return obs, info\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"\n",
    "        One trading step:\n",
    "        - Use current prices S_t and action a_t to compute desired target positions,\n",
    "          following your mapping:\n",
    "            E_t = cash + sum(p_i * S_i_t)\n",
    "            For general N assets:\n",
    "                base_scale = E_t / N\n",
    "                V_i = base_scale * a_i\n",
    "                N_i_target = V_i / S_i_t\n",
    "                Delta_i = N_i_target - p_i\n",
    "        - Apply trades, charge transaction cost on traded notional\n",
    "        - Move to next time t+1, compute portfolio return as reward\n",
    "        \"\"\"\n",
    "        # Clip action into [-1,1]\n",
    "        action = np.clip(action, -1.0, 1.0).astype(np.float32)\n",
    "        price_t = self.prices[self.t]  # prices at time t\n",
    "        price_tp1 = self.prices[self.t + 1] if self.t + 1 < self.T else price_t\n",
    "\n",
    "        # 1. Compute current equity before trades\n",
    "        current_position_value = np.sum(self.positions * price_t)\n",
    "        self.equity = self.cash + current_position_value\n",
    "\n",
    "        # 2. Mapping: compute target dollar exposure and shares\n",
    "        base_scale = self.equity / float(self.n_assets)  # E / N\n",
    "        target_values = base_scale * action  # V_i = E/N * a_i\n",
    "\n",
    "        # Convert target dollar values to target positions (in shares)\n",
    "        target_positions = np.where(\n",
    "            price_t > 0,\n",
    "            target_values / price_t,\n",
    "            0.0,\n",
    "        ).astype(np.float32)\n",
    "\n",
    "        # Trade size (Delta_i)\n",
    "        trade_shares = target_positions - self.positions  # + buy, - sell\n",
    "\n",
    "        # 3. Apply trades, charge transaction cost\n",
    "        trade_values = trade_shares * price_t  # signed trade notional per asset\n",
    "        # total dollar turnover (absolute)\n",
    "        dollar_turnover = np.sum(np.abs(trade_values))\n",
    "        transaction_costs = self.transaction_cost * dollar_turnover\n",
    "\n",
    "        # Update cash and positions:\n",
    "        self.cash = self.cash - np.sum(trade_values) - transaction_costs\n",
    "        self.positions = self.positions + trade_shares\n",
    "\n",
    "        # 4. Move to t+1 and compute new portfolio value\n",
    "        new_position_value = np.sum(self.positions * price_tp1)\n",
    "        new_equity = self.cash + new_position_value\n",
    "\n",
    "        # Reward: simple portfolio return from t to t+1\n",
    "        reward = (new_equity - self.equity) / (self.equity + 1e-8)\n",
    "\n",
    "        # Update equity and time\n",
    "        self.equity = new_equity\n",
    "        self.t += 1\n",
    "\n",
    "        # Episode termination: reached last usable time index\n",
    "        terminated = self.t >= self.T - 1\n",
    "        truncated = False  # 可以加 max_steps 等逻辑，这里先不截断\n",
    "\n",
    "        obs = self._get_observation()\n",
    "        info = {\n",
    "            \"equity\": self.equity,\n",
    "            \"cash\": self.cash,\n",
    "            \"positions\": self.positions.copy(),\n",
    "        }\n",
    "\n",
    "        # Gymnasium: (obs, reward, terminated, truncated, info)\n",
    "        return obs, float(reward), terminated, truncated, info\n",
    "\n",
    "    def render(self):\n",
    "        print(\n",
    "            f\"t={self.t}, equity={self.equity:.2f}, cash={self.cash:.2f}, \"\n",
    "            f\"positions={self.positions}\"\n",
    "        )\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# 2. PPO Agent\n",
    "# ==========================\n",
    "\n",
    "class PolicyValueNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Shared base network with separate policy (mean) and value heads.\n",
    "    Output distribution is Normal; actions are later clipped into [-1,1].\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, obs_dim, action_dim, hidden_sizes=(128, 128)):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        input_dim = obs_dim\n",
    "        for h in hidden_sizes:\n",
    "            layers.append(nn.Linear(input_dim, h))\n",
    "            layers.append(nn.ReLU())\n",
    "            input_dim = h\n",
    "        self.base = nn.Sequential(*layers)\n",
    "\n",
    "        self.mu_head = nn.Linear(input_dim, action_dim)\n",
    "        self.log_std = nn.Parameter(torch.zeros(action_dim))\n",
    "        self.value_head = nn.Linear(input_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        base = self.base(x)\n",
    "        # keep mean in [-1,1] via tanh; we still use Normal and clip later\n",
    "        mu = torch.tanh(self.mu_head(base))\n",
    "        std = torch.exp(self.log_std)\n",
    "        value = self.value_head(base).squeeze(-1)\n",
    "        return mu, std, value\n",
    "\n",
    "    def get_dist_and_value(self, obs):\n",
    "        mu, std, value = self.forward(obs)\n",
    "        dist = Normal(mu, std)\n",
    "        return dist, value\n",
    "\n",
    "\n",
    "class PPOAgent:\n",
    "    def __init__(\n",
    "        self,\n",
    "        obs_dim,\n",
    "        action_dim,\n",
    "        lr=3e-4,\n",
    "        gamma=0.99,\n",
    "        lam=0.95,\n",
    "        clip_ratio=0.2,\n",
    "        vf_coef=0.5,\n",
    "        ent_coef=0.0,\n",
    "        max_grad_norm=0.5,\n",
    "        device=None,\n",
    "    ):\n",
    "        self.device = device or (\n",
    "            \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        )\n",
    "\n",
    "        self.gamma = gamma\n",
    "        self.lam = lam\n",
    "        self.clip_ratio = clip_ratio\n",
    "        self.vf_coef = vf_coef\n",
    "        self.ent_coef = ent_coef\n",
    "        self.max_grad_norm = max_grad_norm\n",
    "\n",
    "        self.net = PolicyValueNet(obs_dim, action_dim).to(self.device)\n",
    "        self.optimizer = torch.optim.Adam(self.net.parameters(), lr=lr)\n",
    "\n",
    "    def act(self, obs):\n",
    "        \"\"\"\n",
    "        Given a single observation (numpy array), return action (numpy),\n",
    "        log_prob, and value estimate.\n",
    "        \"\"\"\n",
    "        obs_t = torch.as_tensor(obs, dtype=torch.float32, device=self.device).unsqueeze(0)\n",
    "        dist, value = self.net.get_dist_and_value(obs_t)\n",
    "        action = dist.sample()\n",
    "        log_prob = dist.log_prob(action).sum(-1)\n",
    "        action_np = action.squeeze(0).cpu().numpy()\n",
    "        log_prob_np = log_prob.item()\n",
    "        value_np = value.item()\n",
    "        return np.clip(action_np, -1.0, 1.0), log_prob_np, value_np\n",
    "\n",
    "    def compute_gae(self, rewards, values, dones, last_value):\n",
    "        \"\"\"\n",
    "        Generalized Advantage Estimation (GAE-Lambda)\n",
    "        rewards, values, dones: numpy arrays length T\n",
    "        last_value: scalar, V(s_{T})\n",
    "        \"\"\"\n",
    "        T = len(rewards)\n",
    "        adv = np.zeros(T, dtype=np.float32)\n",
    "        last_adv = 0.0\n",
    "        for t in reversed(range(T)):\n",
    "            mask = 1.0 - float(dones[t])\n",
    "            delta = rewards[t] + self.gamma * last_value * mask - values[t]\n",
    "            last_adv = delta + self.gamma * self.lam * mask * last_adv\n",
    "            adv[t] = last_adv\n",
    "            last_value = values[t]\n",
    "        returns = values + adv\n",
    "        return adv, returns\n",
    "\n",
    "    def update(self, batch, epochs=10, batch_size=64):\n",
    "        \"\"\"\n",
    "        batch: dict with keys\n",
    "            'obs', 'actions', 'log_probs', 'returns', 'advantages'\n",
    "        \"\"\"\n",
    "        obs = torch.as_tensor(batch[\"obs\"], dtype=torch.float32, device=self.device)\n",
    "        actions = torch.as_tensor(batch[\"actions\"], dtype=torch.float32, device=self.device)\n",
    "        old_log_probs = torch.as_tensor(batch[\"log_probs\"], dtype=torch.float32, device=self.device)\n",
    "        returns = torch.as_tensor(batch[\"returns\"], dtype=torch.float32, device=self.device)\n",
    "        advantages = torch.as_tensor(batch[\"advantages\"], dtype=torch.float32, device=self.device)\n",
    "\n",
    "        advantages = (advantages - advantages.mean()) / (advantages.std() + 1e-8)\n",
    "\n",
    "        n = obs.size(0)\n",
    "        idxs = np.arange(n)\n",
    "\n",
    "        for _ in range(epochs):\n",
    "            np.random.shuffle(idxs)\n",
    "            for start in range(0, n, batch_size):\n",
    "                end = start + batch_size\n",
    "                mb_idx = idxs[start:end]\n",
    "\n",
    "                mb_obs = obs[mb_idx]\n",
    "                mb_actions = actions[mb_idx]\n",
    "                mb_old_log_probs = old_log_probs[mb_idx]\n",
    "                mb_returns = returns[mb_idx]\n",
    "                mb_advantages = advantages[mb_idx]\n",
    "\n",
    "                dist, values = self.net.get_dist_and_value(mb_obs)\n",
    "                new_log_probs = dist.log_prob(mb_actions).sum(-1)\n",
    "                entropy = dist.entropy().sum(-1).mean()\n",
    "\n",
    "                # Policy loss (clipped surrogate objective)\n",
    "                ratio = torch.exp(new_log_probs - mb_old_log_probs)\n",
    "                surr1 = ratio * mb_advantages\n",
    "                surr2 = torch.clamp(\n",
    "                    ratio,\n",
    "                    1.0 - self.clip_ratio,\n",
    "                    1.0 + self.clip_ratio\n",
    "                ) * mb_advantages\n",
    "                policy_loss = -torch.min(surr1, surr2).mean()\n",
    "\n",
    "                # Value loss\n",
    "                value_loss = nn.functional.mse_loss(values, mb_returns)\n",
    "\n",
    "                # Total loss\n",
    "                loss = policy_loss + self.vf_coef * value_loss - self.ent_coef * entropy\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                nn.utils.clip_grad_norm_(self.net.parameters(), self.max_grad_norm)\n",
    "                self.optimizer.step()\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# 3. Minimal training loop (compatible with gymnasium)\n",
    "# ==========================\n",
    "\n",
    "def train_ppo_on_env(\n",
    "    env: MultiAssetTradingEnv,\n",
    "    agent: PPOAgent,\n",
    "    total_steps: int = 50_000,\n",
    "    rollout_horizon: int = 512,\n",
    "):\n",
    "    \"\"\"\n",
    "    Minimal PPO training loop.\n",
    "    You can adapt this to log training curves, save models, etc.\n",
    "    \"\"\"\n",
    "    obs, info = env.reset()\n",
    "    step_count = 0\n",
    "\n",
    "    while step_count < total_steps:\n",
    "        # Collect one rollout\n",
    "        obs_buf = []\n",
    "        act_buf = []\n",
    "        logp_buf = []\n",
    "        rew_buf = []\n",
    "        val_buf = []\n",
    "        done_buf = []\n",
    "\n",
    "        for _ in range(rollout_horizon):\n",
    "            action, logp, value = agent.act(obs)\n",
    "            next_obs, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "            done = terminated or truncated\n",
    "\n",
    "            obs_buf.append(obs)\n",
    "            act_buf.append(action)\n",
    "            logp_buf.append(logp)\n",
    "            rew_buf.append(reward)\n",
    "            val_buf.append(value)\n",
    "            done_buf.append(done)\n",
    "\n",
    "            obs = next_obs\n",
    "            step_count += 1\n",
    "\n",
    "            if done:\n",
    "                obs, info = env.reset()\n",
    "\n",
    "            if step_count >= total_steps:\n",
    "                break\n",
    "\n",
    "        # Compute advantage & returns using last value estimate\n",
    "        with torch.no_grad():\n",
    "            last_value = agent.net.get_dist_and_value(\n",
    "                torch.as_tensor(\n",
    "                    obs, dtype=torch.float32, device=agent.device\n",
    "                ).unsqueeze(0)\n",
    "            )[1].item()\n",
    "\n",
    "        obs_arr = np.array(obs_buf, dtype=np.float32)\n",
    "        act_arr = np.array(act_buf, dtype=np.float32)\n",
    "        logp_arr = np.array(logp_buf, dtype=np.float32)\n",
    "        rew_arr = np.array(rew_buf, dtype=np.float32)\n",
    "        val_arr = np.array(val_buf, dtype=np.float32)\n",
    "        done_arr = np.array(done_buf, dtype=bool)\n",
    "\n",
    "        adv, ret = agent.compute_gae(rew_arr, val_arr, done_arr, last_value)\n",
    "\n",
    "        batch = {\n",
    "            \"obs\": obs_arr,\n",
    "            \"actions\": act_arr,\n",
    "            \"log_probs\": logp_arr,\n",
    "            \"returns\": ret,\n",
    "            \"advantages\": adv,\n",
    "        }\n",
    "\n",
    "        agent.update(batch)\n",
    "\n",
    "        print(f\"Trained up to step {step_count}\")\n",
    "\n",
    "    print(\"Training finished.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e2ad0c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained up to step 256\n",
      "Trained up to step 512\n",
      "Trained up to step 768\n",
      "Trained up to step 1024\n",
      "Trained up to step 1280\n",
      "Trained up to step 1536\n",
      "Trained up to step 1792\n",
      "Trained up to step 2048\n",
      "Trained up to step 2304\n",
      "Trained up to step 2560\n",
      "Trained up to step 2816\n",
      "Trained up to step 3072\n",
      "Trained up to step 3328\n",
      "Trained up to step 3584\n",
      "Trained up to step 3840\n",
      "Trained up to step 4096\n",
      "Trained up to step 4352\n",
      "Trained up to step 4608\n",
      "Trained up to step 4864\n",
      "Trained up to step 5000\n",
      "Training finished.\n"
     ]
    }
   ],
   "source": [
    "# ==========================\n",
    "# Example usage with dummy data\n",
    "# ==========================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example: 5 ETFs, 1000 days, 20 signals per day\n",
    "    T = 1000\n",
    "    N_assets = 5\n",
    "    F = 20\n",
    "\n",
    "    # Dummy price paths (random walk)\n",
    "    rng = np.random.default_rng(42)\n",
    "    log_returns = rng.normal(0, 0.01, size=(T, N_assets))\n",
    "    prices = 100 * np.exp(np.cumsum(log_returns, axis=0)).astype(np.float32)\n",
    "\n",
    "    # Dummy features (here just some random numbers; in your project use real signals)\n",
    "    features = rng.normal(size=(T, F)).astype(np.float32)\n",
    "\n",
    "    env = MultiAssetTradingEnv(\n",
    "        prices=prices,\n",
    "        features=features,\n",
    "        initial_cash=100000.0,\n",
    "        transaction_cost=0.0005,\n",
    "    )\n",
    "    ppo_agent = PPOAgent(\n",
    "        obs_dim=env.obs_dim,\n",
    "        action_dim=env.n_assets,\n",
    "        lr=3e-4,\n",
    "        gamma=0.99,\n",
    "        lam=0.95,\n",
    "        clip_ratio=0.2,\n",
    "    )\n",
    "\n",
    "    train_ppo_on_env(env, ppo_agent, total_steps=5000, rollout_horizon=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bc4f51b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy\n",
      "  Downloading numpy-2.2.6-cp310-cp310-win_amd64.whl.metadata (60 kB)\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.3.3-cp310-cp310-win_amd64.whl.metadata (19 kB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Ignored the following versions that require a different python version: 2.3.0 Requires-Python >=3.11; 2.3.1 Requires-Python >=3.11; 2.3.2 Requires-Python >=3.11; 2.3.3 Requires-Python >=3.11; 2.3.4 Requires-Python >=3.11; 2.3.5 Requires-Python >=3.11; 2.4.0rc1 Requires-Python >=3.11; 3.0.0rc0 Requires-Python >=3.11\n",
      "ERROR: Could not find a version that satisfies the requirement matpolib (from versions: none)\n",
      "ERROR: No matching distribution found for matpolib\n"
     ]
    }
   ],
   "source": [
    "! pip install numpy pandas matpolib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17634e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy\n",
      "  Using cached numpy-2.2.6-cp310-cp310-win_amd64.whl.metadata (60 kB)\n",
      "Downloading numpy-2.2.6-cp310-cp310-win_amd64.whl (12.9 MB)\n",
      "   ---------------------------------------- 0.0/12.9 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.9 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.8/12.9 MB 2.6 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 1.6/12.9 MB 3.4 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 2.6/12.9 MB 3.7 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 3.4/12.9 MB 3.7 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 4.7/12.9 MB 4.1 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 6.0/12.9 MB 4.6 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 7.3/12.9 MB 4.7 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 8.4/12.9 MB 4.7 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 9.4/12.9 MB 4.9 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 10.5/12.9 MB 4.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 11.8/12.9 MB 5.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.9/12.9 MB 5.2 MB/s  0:00:02\n",
      "Installing collected packages: numpy\n",
      "Successfully installed numpy-2.2.6\n",
      "Collecting gymnasium>=0.29.0\n",
      "  Downloading gymnasium-1.2.2-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy>=1.21.0 in d:\\anaconda3\\envs\\rltrading\\lib\\site-packages (from gymnasium>=0.29.0) (2.2.6)\n",
      "Collecting cloudpickle>=1.2.0 (from gymnasium>=0.29.0)\n",
      "  Downloading cloudpickle-3.1.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in d:\\anaconda3\\envs\\rltrading\\lib\\site-packages (from gymnasium>=0.29.0) (4.15.0)\n",
      "Collecting farama-notifications>=0.0.1 (from gymnasium>=0.29.0)\n",
      "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl.metadata (558 bytes)\n",
      "Downloading gymnasium-1.2.2-py3-none-any.whl (952 kB)\n",
      "   ---------------------------------------- 0.0/952.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 952.1/952.1 kB 22.3 MB/s  0:00:00\n",
      "Downloading cloudpickle-3.1.2-py3-none-any.whl (22 kB)\n",
      "Downloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
      "Installing collected packages: farama-notifications, cloudpickle, gymnasium\n",
      "\n",
      "   -------------------------- ------------- 2/3 [gymnasium]\n",
      "   -------------------------- ------------- 2/3 [gymnasium]\n",
      "   ---------------------------------------- 3/3 [gymnasium]\n",
      "\n",
      "Successfully installed cloudpickle-3.1.2 farama-notifications-0.0.4 gymnasium-1.2.2\n",
      "Collecting torch>=2.2.0\n",
      "  Downloading torch-2.9.1-cp310-cp310-win_amd64.whl.metadata (30 kB)\n",
      "Collecting filelock (from torch>=2.2.0)\n",
      "  Downloading filelock-3.20.0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in d:\\anaconda3\\envs\\rltrading\\lib\\site-packages (from torch>=2.2.0) (4.15.0)\n",
      "Collecting sympy>=1.13.3 (from torch>=2.2.0)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx>=2.5.1 (from torch>=2.2.0)\n",
      "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting jinja2 (from torch>=2.2.0)\n",
      "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting fsspec>=0.8.5 (from torch>=2.2.0)\n",
      "  Downloading fsspec-2025.12.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch>=2.2.0)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch>=2.2.0)\n",
      "  Downloading markupsafe-3.0.3-cp310-cp310-win_amd64.whl.metadata (2.8 kB)\n",
      "Downloading torch-2.9.1-cp310-cp310-win_amd64.whl (111.0 MB)\n",
      "   ---------------------------------------- 0.0/111.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.5/111.0 MB 2.8 MB/s eta 0:00:40\n",
      "   ---------------------------------------- 1.0/111.0 MB 2.5 MB/s eta 0:00:44\n",
      "    --------------------------------------- 1.8/111.0 MB 3.0 MB/s eta 0:00:37\n",
      "    --------------------------------------- 2.6/111.0 MB 3.3 MB/s eta 0:00:34\n",
      "   - -------------------------------------- 3.4/111.0 MB 3.5 MB/s eta 0:00:31\n",
      "   - -------------------------------------- 4.2/111.0 MB 3.5 MB/s eta 0:00:31\n",
      "   - -------------------------------------- 5.2/111.0 MB 3.7 MB/s eta 0:00:29\n",
      "   -- ------------------------------------- 6.3/111.0 MB 3.9 MB/s eta 0:00:27\n",
      "   -- ------------------------------------- 7.3/111.0 MB 4.0 MB/s eta 0:00:26\n",
      "   --- ------------------------------------ 8.4/111.0 MB 4.1 MB/s eta 0:00:26\n",
      "   --- ------------------------------------ 9.4/111.0 MB 4.3 MB/s eta 0:00:24\n",
      "   --- ------------------------------------ 11.0/111.0 MB 4.5 MB/s eta 0:00:23\n",
      "   ---- ----------------------------------- 12.3/111.0 MB 4.6 MB/s eta 0:00:22\n",
      "   ----- ---------------------------------- 14.4/111.0 MB 5.0 MB/s eta 0:00:20\n",
      "   ----- ---------------------------------- 16.5/111.0 MB 5.4 MB/s eta 0:00:18\n",
      "   ------ --------------------------------- 18.9/111.0 MB 5.8 MB/s eta 0:00:17\n",
      "   ------- -------------------------------- 20.4/111.0 MB 5.9 MB/s eta 0:00:16\n",
      "   -------- ------------------------------- 22.5/111.0 MB 6.1 MB/s eta 0:00:15\n",
      "   --------- ------------------------------ 25.2/111.0 MB 6.4 MB/s eta 0:00:14\n",
      "   --------- ------------------------------ 27.0/111.0 MB 6.6 MB/s eta 0:00:13\n",
      "   ---------- ----------------------------- 28.6/111.0 MB 6.6 MB/s eta 0:00:13\n",
      "   ---------- ----------------------------- 30.1/111.0 MB 6.7 MB/s eta 0:00:13\n",
      "   ------------ --------------------------- 33.3/111.0 MB 7.0 MB/s eta 0:00:12\n",
      "   ------------ --------------------------- 35.9/111.0 MB 7.2 MB/s eta 0:00:11\n",
      "   ------------- -------------------------- 38.3/111.0 MB 7.4 MB/s eta 0:00:10\n",
      "   -------------- ------------------------- 41.4/111.0 MB 7.7 MB/s eta 0:00:10\n",
      "   --------------- ------------------------ 44.3/111.0 MB 7.9 MB/s eta 0:00:09\n",
      "   ---------------- ----------------------- 46.4/111.0 MB 8.0 MB/s eta 0:00:09\n",
      "   ----------------- ---------------------- 49.8/111.0 MB 8.3 MB/s eta 0:00:08\n",
      "   ------------------ --------------------- 52.7/111.0 MB 8.5 MB/s eta 0:00:07\n",
      "   -------------------- ------------------- 56.6/111.0 MB 8.8 MB/s eta 0:00:07\n",
      "   --------------------- ------------------ 59.8/111.0 MB 9.0 MB/s eta 0:00:06\n",
      "   --------------------- ------------------ 60.8/111.0 MB 9.0 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 64.5/111.0 MB 9.2 MB/s eta 0:00:06\n",
      "   ------------------------ --------------- 68.2/111.0 MB 9.4 MB/s eta 0:00:05\n",
      "   ------------------------- -------------- 71.3/111.0 MB 9.6 MB/s eta 0:00:05\n",
      "   --------------------------- ------------ 75.0/111.0 MB 9.8 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 76.8/111.0 MB 9.9 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 78.1/111.0 MB 9.7 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 81.5/111.0 MB 9.9 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 84.9/111.0 MB 10.1 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 88.3/111.0 MB 10.2 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 91.5/111.0 MB 10.4 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 93.6/111.0 MB 10.5 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 94.6/111.0 MB 10.3 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 97.8/111.0 MB 10.3 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 100.1/111.0 MB 10.4 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 102.8/111.0 MB 10.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 104.9/111.0 MB 10.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  108.3/111.0 MB 10.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  110.9/111.0 MB 10.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 111.0/111.0 MB 10.5 MB/s  0:00:10\n",
      "Downloading fsspec-2025.12.0-py3-none-any.whl (201 kB)\n",
      "Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.7/1.7 MB 23.2 MB/s  0:00:00\n",
      "Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "   ---------------------------------------- 0.0/6.3 MB ? eta -:--:--\n",
      "   -------------------------- ------------- 4.2/6.3 MB 19.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.3/6.3 MB 16.8 MB/s  0:00:00\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 536.2/536.2 kB 8.8 MB/s  0:00:00\n",
      "Downloading filelock-3.20.0-py3-none-any.whl (16 kB)\n",
      "Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Downloading markupsafe-3.0.3-cp310-cp310-win_amd64.whl (15 kB)\n",
      "Installing collected packages: mpmath, sympy, networkx, MarkupSafe, fsspec, filelock, jinja2, torch\n",
      "\n",
      "   ---------------------------------------- 0/8 [mpmath]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ----- ---------------------------------- 1/8 [sympy]\n",
      "   ---------- ----------------------------- 2/8 [networkx]\n",
      "   ---------- ----------------------------- 2/8 [networkx]\n",
      "   ---------- ----------------------------- 2/8 [networkx]\n",
      "   ---------- ----------------------------- 2/8 [networkx]\n",
      "   ---------- ----------------------------- 2/8 [networkx]\n",
      "   -------------------- ------------------- 4/8 [fsspec]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ----------------------------------- ---- 7/8 [torch]\n",
      "   ---------------------------------------- 8/8 [torch]\n",
      "\n",
      "Successfully installed MarkupSafe-3.0.3 filelock-3.20.0 fsspec-2025.12.0 jinja2-3.1.6 mpmath-1.3.0 networkx-3.4.2 sympy-1.14.0 torch-2.9.1\n"
     ]
    }
   ],
   "source": [
    "! pip install numpy\n",
    "! pip install \"gymnasium>=0.29.0\"\n",
    "! pip install \"torch>=2.2.0\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "181ef6d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Using cached pandas-2.3.3-cp310-cp310-win_amd64.whl.metadata (19 kB)\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.7-cp310-cp310-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy>=1.22.4 in d:\\anaconda3\\envs\\rltrading\\lib\\site-packages (from pandas) (2.2.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\anaconda3\\envs\\rltrading\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.2-cp310-cp310-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.61.0-cp310-cp310-win_amd64.whl.metadata (115 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.9-cp310-cp310-win_amd64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\anaconda3\\envs\\rltrading\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Downloading pillow-12.0.0-cp310-cp310-win_amd64.whl.metadata (9.0 kB)\n",
      "Collecting pyparsing>=3 (from matplotlib)\n",
      "  Downloading pyparsing-3.2.5-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: six>=1.5 in d:\\anaconda3\\envs\\rltrading\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading pandas-2.3.3-cp310-cp310-win_amd64.whl (11.3 MB)\n",
      "   ---------------------------------------- 0.0/11.3 MB ? eta -:--:--\n",
      "   -------------------- ------------------- 5.8/11.3 MB 32.0 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 7.9/11.3 MB 32.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.3/11.3 MB 18.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.3/11.3 MB 17.7 MB/s  0:00:00\n",
      "Downloading matplotlib-3.10.7-cp310-cp310-win_amd64.whl (8.1 MB)\n",
      "   ---------------------------------------- 0.0/8.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 8.1/8.1 MB 45.6 MB/s  0:00:00\n",
      "Downloading contourpy-1.3.2-cp310-cp310-win_amd64.whl (221 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.61.0-cp310-cp310-win_amd64.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.5/1.5 MB 27.3 MB/s  0:00:00\n",
      "Downloading kiwisolver-1.4.9-cp310-cp310-win_amd64.whl (73 kB)\n",
      "Downloading pillow-12.0.0-cp310-cp310-win_amd64.whl (7.0 MB)\n",
      "   ---------------------------------------- 0.0/7.0 MB ? eta -:--:--\n",
      "   -------------------------------------- - 6.8/7.0 MB 32.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 7.0/7.0 MB 28.8 MB/s  0:00:00\n",
      "Downloading pyparsing-3.2.5-py3-none-any.whl (113 kB)\n",
      "Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: pytz, tzdata, pyparsing, pillow, kiwisolver, fonttools, cycler, contourpy, pandas, matplotlib\n",
      "\n",
      "   ---- -----------------------------------  1/10 [tzdata]\n",
      "   -------- -------------------------------  2/10 [pyparsing]\n",
      "   ------------ ---------------------------  3/10 [pillow]\n",
      "   -------------------- -------------------  5/10 [fonttools]\n",
      "   -------------------- -------------------  5/10 [fonttools]\n",
      "   -------------------- -------------------  5/10 [fonttools]\n",
      "   -------------------- -------------------  5/10 [fonttools]\n",
      "   -------------------------------- -------  8/10 [pandas]\n",
      "   -------------------------------- -------  8/10 [pandas]\n",
      "   -------------------------------- -------  8/10 [pandas]\n",
      "   -------------------------------- -------  8/10 [pandas]\n",
      "   -------------------------------- -------  8/10 [pandas]\n",
      "   -------------------------------- -------  8/10 [pandas]\n",
      "   -------------------------------- -------  8/10 [pandas]\n",
      "   -------------------------------- -------  8/10 [pandas]\n",
      "   -------------------------------- -------  8/10 [pandas]\n",
      "   -------------------------------- -------  8/10 [pandas]\n",
      "   -------------------------------- -------  8/10 [pandas]\n",
      "   -------------------------------- -------  8/10 [pandas]\n",
      "   -------------------------------- -------  8/10 [pandas]\n",
      "   -------------------------------- -------  8/10 [pandas]\n",
      "   -------------------------------- -------  8/10 [pandas]\n",
      "   -------------------------------- -------  8/10 [pandas]\n",
      "   -------------------------------- -------  8/10 [pandas]\n",
      "   -------------------------------- -------  8/10 [pandas]\n",
      "   -------------------------------- -------  8/10 [pandas]\n",
      "   -------------------------------- -------  8/10 [pandas]\n",
      "   -------------------------------- -------  8/10 [pandas]\n",
      "   -------------------------------- -------  8/10 [pandas]\n",
      "   -------------------------------- -------  8/10 [pandas]\n",
      "   -------------------------------- -------  8/10 [pandas]\n",
      "   -------------------------------- -------  8/10 [pandas]\n",
      "   -------------------------------- -------  8/10 [pandas]\n",
      "   -------------------------------- -------  8/10 [pandas]\n",
      "   -------------------------------- -------  8/10 [pandas]\n",
      "   -------------------------------- -------  8/10 [pandas]\n",
      "   -------------------------------- -------  8/10 [pandas]\n",
      "   -------------------------------- -------  8/10 [pandas]\n",
      "   -------------------------------- -------  8/10 [pandas]\n",
      "   -------------------------------- -------  8/10 [pandas]\n",
      "   ------------------------------------ ---  9/10 [matplotlib]\n",
      "   ------------------------------------ ---  9/10 [matplotlib]\n",
      "   ------------------------------------ ---  9/10 [matplotlib]\n",
      "   ------------------------------------ ---  9/10 [matplotlib]\n",
      "   ------------------------------------ ---  9/10 [matplotlib]\n",
      "   ------------------------------------ ---  9/10 [matplotlib]\n",
      "   ------------------------------------ ---  9/10 [matplotlib]\n",
      "   ------------------------------------ ---  9/10 [matplotlib]\n",
      "   ------------------------------------ ---  9/10 [matplotlib]\n",
      "   ------------------------------------ ---  9/10 [matplotlib]\n",
      "   ---------------------------------------- 10/10 [matplotlib]\n",
      "\n",
      "Successfully installed contourpy-1.3.2 cycler-0.12.1 fonttools-4.61.0 kiwisolver-1.4.9 matplotlib-3.10.7 pandas-2.3.3 pillow-12.0.0 pyparsing-3.2.5 pytz-2025.2 tzdata-2025.2\n"
     ]
    }
   ],
   "source": [
    "! pip install pandas matplotlib\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rltrading",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
